<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>异步编程:从高并发爬虫看异步编程 | A2u13's Blog</title><meta name="description" content="本文内容： python当中的异步并发编程以及编程实例   python相关模块相关模块以及调用方法 Python 中 concurrent.futures 模块使用说明 gevent python之gevent（1） 实例这里我会根据实际的一个高并发爬虫来演示如何利用多进程、多线程以及协程进行组合从而实现一个并发数可控的高并发爬虫 我们这里目标选择https:&#x2F;&#x2F;www.52bqg.com&#x2F;bo"><meta name="keywords" content="异步编程"><meta name="author" content="A2u13"><meta name="copyright" content="A2u13"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/favicon.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="http://ta.qq.com"/><link rel="dns-prefetch" href="http://ta.qq.com"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="异步编程:从高并发爬虫看异步编程"><meta name="twitter:description" content="本文内容： python当中的异步并发编程以及编程实例   python相关模块相关模块以及调用方法 Python 中 concurrent.futures 模块使用说明 gevent python之gevent（1） 实例这里我会根据实际的一个高并发爬虫来演示如何利用多进程、多线程以及协程进行组合从而实现一个并发数可控的高并发爬虫 我们这里目标选择https:&#x2F;&#x2F;www.52bqg.com&#x2F;bo"><meta name="twitter:image" content="https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/20200529223726.png"><meta property="og:type" content="article"><meta property="og:title" content="异步编程:从高并发爬虫看异步编程"><meta property="og:url" content="https://a2u13.com/2020/04/14/%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B-%E4%BB%8E%E9%AB%98%E5%B9%B6%E5%8F%91%E7%88%AC%E8%99%AB%E7%9C%8B%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/"><meta property="og:site_name" content="A2u13's Blog"><meta property="og:description" content="本文内容： python当中的异步并发编程以及编程实例   python相关模块相关模块以及调用方法 Python 中 concurrent.futures 模块使用说明 gevent python之gevent（1） 实例这里我会根据实际的一个高并发爬虫来演示如何利用多进程、多线程以及协程进行组合从而实现一个并发数可控的高并发爬虫 我们这里目标选择https:&#x2F;&#x2F;www.52bqg.com&#x2F;bo"><meta property="og:image" content="https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/20200529223726.png"><meta property="article:published_time" content="2020-04-14T04:02:29.000Z"><meta property="article:modified_time" content="2020-06-07T06:28:28.914Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="https://a2u13.com/2020/04/14/%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B-%E4%BB%8E%E9%AB%98%E5%B9%B6%E5%8F%91%E7%88%AC%E8%99%AB%E7%9C%8B%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/"><link rel="prev" title="JavaScript闭包" href="https://a2u13.com/2020/06/06/JavaScript%E9%97%AD%E5%8C%85/"><link rel="next" title="入侵响应与应急整理" href="https://a2u13.com/2020/03/28/%E5%85%A5%E4%BE%B5%E5%93%8D%E5%BA%94%E4%B8%8E%E5%BA%94%E6%80%A5%E6%95%B4%E7%90%86/"><script src="https://tajs.qq.com/stats?sId=&lt;script type=&quot;text/javascript&quot; src=&quot;http://tajs.qq.com/stats?sId=66562096&quot; charset=&quot;UTF-8&quot;&gt;&lt;/script&gt;" charset="UTF-8"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://a2u13.com/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: false,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  highlightCopy: true,
  highlightLang: false,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="A2u13's Blog" type="application/atom+xml">
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/4A56A073590349364F32B58397E8B06C.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">36</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">23</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">15</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#python相关模块"><span class="toc-number">1.</span> <span class="toc-text">python相关模块</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#实例"><span class="toc-number">2.</span> <span class="toc-text">实例</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#链接爬取"><span class="toc-number">2.1.</span> <span class="toc-text">链接爬取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#链接分组"><span class="toc-number">2.2.</span> <span class="toc-text">链接分组</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多进程设计"><span class="toc-number">2.3.</span> <span class="toc-text">多进程设计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多线程设计"><span class="toc-number">2.4.</span> <span class="toc-text">多线程设计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#协程设计"><span class="toc-number">2.5.</span> <span class="toc-text">协程设计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#全部代码"><span class="toc-number">2.6.</span> <span class="toc-text">全部代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#效果"><span class="toc-number">2.7.</span> <span class="toc-text">效果</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总结"><span class="toc-number">3.</span> <span class="toc-text">总结</span></a></li></ol></div></div></div><div id="body-wrap"><div id="web_bg" data-type="photo"></div><div class="post-bg" id="nav" style="background-image: url(https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/20200529223726.png)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">A2u13's Blog</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">异步编程:从高并发爬虫看异步编程</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-04-14 12:02:29"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-04-14</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-06-07 14:28:28"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-06-07</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%AE%89%E5%85%A8%E7%A0%94%E5%8F%91/">安全研发</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">2.1k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 7 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p><strong>本文内容：</strong></p>
<p>python当中的异步并发编程以及编程实例</p>
<a id="more"></a>

<h1 id="python相关模块"><a href="#python相关模块" class="headerlink" title="python相关模块"></a>python相关模块</h1><p>相关模块以及调用方法</p>
<p><a href="https://blog.csdn.net/jpch89/article/details/87643972" target="_blank" rel="noopener">Python 中 concurrent.futures 模块使用说明</a></p>
<p><a href="https://www.liaoxuefeng.com/wiki/897692888725344/966405998508320" target="_blank" rel="noopener">gevent</a></p>
<p><a href="https://www.jianshu.com/p/bb6c7f9aa1ae" target="_blank" rel="noopener">python之gevent（1）</a></p>
<h1 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h1><p>这里我会根据实际的一个高并发爬虫来演示如何利用多进程、多线程以及协程进行组合从而实现一个并发数可控的高并发爬虫</p>
<p>我们这里目标选择<a href="https://www.52bqg.com/book_203/" target="_blank" rel="noopener">https://www.52bqg.com/book_203/</a></p>
<p>即我以前很喜欢看的<code>校花的贴身高手</code>，目前差不多8300章，很适合测试爬虫效率</p>
<h2 id="链接爬取"><a href="#链接爬取" class="headerlink" title="链接爬取"></a>链接爬取</h2><p>对于连接的爬取，这里采用一开始就先在主线程进行调用，将所有的章节的<code>href</code>存到一个列表之后进行下一步操作</p>
<p>这里也可以设计成一个单独的进程处理连接爬取任务，主要的额外操作在于需要设置<code>Lock</code>或者<code>Semaphore</code>来进行同步，让子进程处理完连接爬取任务后从而释放锁，进行下一步的并发爬虫操作，这里我们先简单使用列表进行连接存储，以后会进行改进使用队列</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getIndexUrl</span><span class="params">(indexUrl)</span>:</span></span><br><span class="line">    allUrls = []</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = session.get(url=indexUrl)</span><br><span class="line">        bs = BeautifulSoup(res.content.decode(<span class="string">"GBK"</span>), <span class="string">"lxml"</span>)</span><br><span class="line">        lists = bs.find(<span class="string">"div"</span>, id=<span class="string">"list"</span>)</span><br><span class="line">        dd = lists.find_all(<span class="string">"dd"</span>)</span><br><span class="line">        <span class="keyword">for</span> eachdd <span class="keyword">in</span> dd:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                a = eachdd.find(<span class="string">"a"</span>)</span><br><span class="line">                href = a[<span class="string">'href'</span>]</span><br><span class="line">                allUrls.append(indexUrl + href)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span> allUrls</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>这里需要注意的是网页编码</p>
<h2 id="链接分组"><a href="#链接分组" class="headerlink" title="链接分组"></a>链接分组</h2><p>由于采用多进程、多线程和协程组合，所以需要对每一个协程分配任务，这里就需要对链接进行分组，要满足每一个协程都能分配到合适的任务，由于多进程和多线程都需要对链接列表进行分组切割，这里我写了一个<code>splitUrl</code>类用来处理连接分组任务</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">splitUrl</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, splitnum, urls)</span>:</span></span><br><span class="line">        self.splitnum = splitnum</span><br><span class="line">        self.urls = urls</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        num_urls = len(self.urls)</span><br><span class="line">        <span class="keyword">if</span> num_urls &lt; self.splitnum:</span><br><span class="line">            <span class="keyword">return</span> [self.urls]</span><br><span class="line">        perUrlNum = int(num_urls / self.splitnum)</span><br><span class="line">        splitted_urls = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.splitnum):</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                splitted_urls.append(self.urls[: (i + <span class="number">1</span>) * perUrlNum])</span><br><span class="line">            <span class="keyword">elif</span> i == self.splitnum - <span class="number">1</span>:</span><br><span class="line">                splitted_urls.append(self.urls[i * perUrlNum:])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                splitted_urls.append(self.urls[i * perUrlNum: (i + <span class="number">1</span>) * perUrlNum])</span><br><span class="line">        <span class="keyword">return</span> splitted_urls</span><br></pre></td></tr></table></figure>

<p>逻辑很简单，根据设置的分组个数以及总的<code>url</code>列表进行分组，最终效果如下（这里显示为8进程分组）</p>
<p><img src="https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/image-20200414123646833.png" alt="image-20200414123646833"></p>
<h2 id="多进程设计"><a href="#多进程设计" class="headerlink" title="多进程设计"></a>多进程设计</h2><p>多进程我们这里选择采用<code>concurrent.futures</code>作为异步模块，调用其中的<code>ProcessPoolExecutor</code>作为进程池，方便操作系统对进程进行调度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ProcessPoolExecutor, wait, ALL_COMPLETED</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiProcessScheduler</span><span class="params">(splitted_urls)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> CPU_NUM</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        executor = ProcessPoolExecutor(max_workers=CPU_NUM)</span><br><span class="line">        all_tasks = executor.map(threadScheduler, splitted_urls)</span><br><span class="line">        wait(all_tasks, return_when=ALL_COMPLETED)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>这里我们提前在主线程讲所有链接分好组，然后直接在<code>multiProcessScheduler</code>进行调用</p>
<p>首先我们需要获得当前的<code>CPU核数</code>，超过<code>CPU核数</code>的多进程数是没有意义的，反而影响操作系统的进程间调度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> cpu_count</span><br><span class="line">CPU_NUM = cpu_count()</span><br></pre></td></tr></table></figure>

<p>然后实例化<code>ProcessPoolExecutor</code>类，其中每一个进程要执行的是我们下一步要调用的<code>threadScheduler</code>函数，它的参数是我们已经初步分好组的url</p>
<p>采用<code>map</code>函数来进行批量设置（此map函数非python标准库的map函数）</p>
<p>对于单独要设置的任务要采用<code>submit</code>进行手工提交</p>
<blockquote>
<p><code>submit(fn, *args, **kwargs)</code></p>
</blockquote>
<p>安排可调用对象 fn 以 <code>fn(*args, **kwargs)</code> 的形式执行，并返回 <code>Future</code> 对象来表示它的执行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> ThreadPoolExecutor(max_workers=<span class="number">1</span>) <span class="keyword">as</span> executor:</span><br><span class="line">    future = executor.submit(pow, <span class="number">323</span>, <span class="number">1235</span>)</span><br><span class="line">    print(future.result())</span><br></pre></td></tr></table></figure>

<p>这里要注意，必须设置<code>wait</code>来对主线程进行阻塞，退出条件是所有进程中的任务全部完毕时候才会释放对主进程的阻塞，否则主进程提前结束会导致所有的并发失败</p>
<h2 id="多线程设计"><a href="#多线程设计" class="headerlink" title="多线程设计"></a>多线程设计</h2><p>同理，我们需要对多进程传进来的分组url列表进行二次分组，我这里偷懒写入了线程当中，如果想提高速度的话，建议在主线程一开始就分好线程的组</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ThreadPoolExecutor, wait, ALL_COMPLETED</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">threadScheduler</span><span class="params">(urlss)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> THREAD_NUM</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        splitted_urls = splitUrl(THREAD_NUM, urlss).run()</span><br><span class="line">        executor = ThreadPoolExecutor(max_workers=THREAD_NUM)</span><br><span class="line">        all_tasks = executor.map(greenletScheduler, splitted_urls)</span><br><span class="line">        wait(all_tasks, return_when=ALL_COMPLETED)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>这里选择我们开辟的线程池大小，对于每一个线程都调用我们的<code>greenletScheduler</code>函数，即我们的协程</p>
<p>同理需要设置<code>wait</code>需要阻塞线程防止提前结束</p>
<h2 id="协程设计"><a href="#协程设计" class="headerlink" title="协程设计"></a>协程设计</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> gevent <span class="keyword">import</span> monkey</span><br><span class="line"></span><br><span class="line">monkey.patch_all()</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> gevent.pool <span class="keyword">import</span> Pool <span class="keyword">as</span> ge_pool</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greenletScheduler</span><span class="params">(urls)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> GEVENT_NUM</span><br><span class="line">    greenlet_pool = ge_pool(GEVENT_NUM)</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        greenlet_pool.apply_async(getContent, (url,))</span><br><span class="line">    greenlet_pool.join()</span><br></pre></td></tr></table></figure>

<p>这个是专门为了改造所有的模块使之能够变为异步操作，这个需要放到代码最开始的地方从而实现把<code>socket、ssl、threading和 select</code>等模块变为协程，这一过程需要在启动时通过monkey patch完成。</p>
<p>然后创建的我们的协程池，这里将<code>url</code>加入到我们的协程池当中，注意这里采用了<code>apply_async</code>，即异步非阻塞</p>
<figure class="highlight coq"><table><tr><td class="code"><pre><span class="line"><span class="built_in">apply</span>是阻塞式的。</span><br><span class="line"></span><br><span class="line">首先主进程开始运行，碰到子进程，操作系统切换到子进程，等待子进程运行结束后，在切换到另外一个子进程，直到所有子进程运行完毕。然后在切换到主进程，运行剩余的部分。</span><br><span class="line"></span><br><span class="line">apply_async是异步非阻塞式的。</span><br><span class="line"></span><br><span class="line">首先主进程开始运行，碰到子进程后，主进程说：让我先运行个够，等到操作系统进行进程切换的时候，在交给子进程运行。以为我们的程序太短，然而还没等到操作系统进行进程切换，主进程就运行完毕了。</span><br><span class="line">想要子进程执行，就告诉主进程：你等着所有子进程执行完毕后，在运行剩余部分。</span><br></pre></td></tr></table></figure>

<p>反正知道阻塞的会特别慢，直接调用<code>apply_async</code>即可</p>
<p>将所有的任务加到协程池后就<code>join</code>阻塞当前线程直到所有的协程任务完成</p>
<h2 id="全部代码"><a href="#全部代码" class="headerlink" title="全部代码"></a>全部代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> gevent <span class="keyword">import</span> monkey</span><br><span class="line"></span><br><span class="line">monkey.patch_all()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> cpu_count</span><br><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ThreadPoolExecutor, ProcessPoolExecutor, wait, ALL_COMPLETED</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> timeit</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> gevent.pool <span class="keyword">import</span> Pool <span class="keyword">as</span> ge_pool</span><br><span class="line"></span><br><span class="line">session = requests.session()</span><br><span class="line"></span><br><span class="line">indexUrl = <span class="string">"https://www.52bqg.com/book_203/"</span></span><br><span class="line"></span><br><span class="line">CPU_NUM = cpu_count()</span><br><span class="line">THREAD_NUM = <span class="number">4</span></span><br><span class="line">GEVENT_NUM = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">splitUrl</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, splitnum, urls)</span>:</span></span><br><span class="line">        self.splitnum = splitnum</span><br><span class="line">        self.urls = urls</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        num_urls = len(self.urls)</span><br><span class="line">        <span class="keyword">if</span> num_urls &lt; self.splitnum:</span><br><span class="line">            <span class="keyword">return</span> [self.urls]</span><br><span class="line">        perUrlNum = int(num_urls / self.splitnum)</span><br><span class="line">        splitted_urls = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.splitnum):</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                splitted_urls.append(self.urls[: (i + <span class="number">1</span>) * perUrlNum])</span><br><span class="line">            <span class="keyword">elif</span> i == self.splitnum - <span class="number">1</span>:</span><br><span class="line">                splitted_urls.append(self.urls[i * perUrlNum:])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                splitted_urls.append(self.urls[i * perUrlNum: (i + <span class="number">1</span>) * perUrlNum])</span><br><span class="line">        <span class="keyword">return</span> splitted_urls</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getIndexUrl</span><span class="params">(indexUrl)</span>:</span></span><br><span class="line">    allUrls = []</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = session.get(url=indexUrl)</span><br><span class="line">        bs = BeautifulSoup(res.content.decode(<span class="string">"GBK"</span>), <span class="string">"lxml"</span>)</span><br><span class="line">        lists = bs.find(<span class="string">"div"</span>, id=<span class="string">"list"</span>)</span><br><span class="line">        dd = lists.find_all(<span class="string">"dd"</span>)</span><br><span class="line">        <span class="keyword">for</span> eachdd <span class="keyword">in</span> dd:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                a = eachdd.find(<span class="string">"a"</span>)</span><br><span class="line">                href = a[<span class="string">'href'</span>]</span><br><span class="line">                allUrls.append(indexUrl + href)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span> allUrls</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getContent</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = session.get(url)</span><br><span class="line">        bs = BeautifulSoup(res.content.decode(<span class="string">"GBK"</span>), <span class="string">"lxml"</span>)</span><br><span class="line">        content = bs.find(<span class="string">"div"</span>, id=<span class="string">"content"</span>).get_text()</span><br><span class="line">        title = bs.find(<span class="string">"div"</span>, class_=<span class="string">"bookname"</span>).find(<span class="string">"h1"</span>).get_text()</span><br><span class="line">        writeContent(title, content)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">writeContent</span><span class="params">(title, content)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"content/&#123;&#125;.txt"</span>.format(title), <span class="string">"w+"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(content)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiProcessScheduler</span><span class="params">(splitted_urls)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> CPU_NUM</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        executor = ProcessPoolExecutor(max_workers=CPU_NUM)</span><br><span class="line">        all_tasks = executor.map(threadScheduler, splitted_urls)</span><br><span class="line">        wait(all_tasks, return_when=ALL_COMPLETED)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">threadScheduler</span><span class="params">(urlss)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> THREAD_NUM</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        splitted_urls = splitUrl(THREAD_NUM, urlss).run()</span><br><span class="line">        executor = ThreadPoolExecutor(max_workers=THREAD_NUM)</span><br><span class="line">        all_tasks = executor.map(greenletScheduler, splitted_urls)</span><br><span class="line">        wait(all_tasks, return_when=ALL_COMPLETED)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greenletScheduler</span><span class="params">(urls)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> GEVENT_NUM</span><br><span class="line">    greenlet_pool = ge_pool(GEVENT_NUM)</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        greenlet_pool.apply_async(getContent, (url,))</span><br><span class="line">    greenlet_pool.join()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">"content"</span>):</span><br><span class="line">        os.mkdir(<span class="string">"content"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    start = timeit.default_timer()</span><br><span class="line">    allUrls = getIndexUrl(indexUrl)</span><br><span class="line">    splitted_urls = splitUrl(CPU_NUM, allUrls).run()</span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> splitted_urls:</span><br><span class="line">        print(each)</span><br><span class="line">    multiProcessScheduler(splitted_urls)</span><br><span class="line">    end = timeit.default_timer()</span><br><span class="line">    print(str(end - start))</span><br></pre></td></tr></table></figure>

<h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p><img src="https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/image-20200414133610745.png" alt="image-20200414133610745"></p>
<p><img src="https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/image-20200414132119788.png" alt="image-20200414132119788"></p>
<p><img src="https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/image-20200414134148216.png" alt="image-20200414134148216"></p>
<p>可以看到一共27秒即可爬完所有的8300章的小说，比同步一章一章爬取快的不知道哪去了</p>
<p>所以说对于爬虫而言，最好采用异步来加快速度，</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li>异步编程是一门巨坑，如果调度不当的话，很可能陷入巨坑无法自拔，而且多进程这里<code>debug</code>不了，我看网上建议是通过阻塞子进程或者print调试法-_-</li>
<li>现在python3.6出现了<code>asyncio、aiohttp</code>两个异步IO模块，打算下一期使用这两个模块进行改造</li>
<li>异步编程尤其要注意，不要随意增加print等IO操作，否则操作系统还得回来调度IO，增加开销时间</li>
<li>感觉还是很初级，下一次试试采用队列等进行有序归并，顺便看看<code>map_reduce</code>?</li>
</ul>
<p>最重要的是，多进程编程千万不要写递归！！！</p>
<p>否则就会这样↓↓↓↓↓↓↓↓</p>
<p><img src="https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/BAFB3972931871C4D9A49477A2326D7F.jpg" alt="BAFB3972931871C4D9A49477A2326D7F"></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">A2u13</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://a2u13.com/2020/04/14/%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B-%E4%BB%8E%E9%AB%98%E5%B9%B6%E5%8F%91%E7%88%AC%E8%99%AB%E7%9C%8B%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/">https://a2u13.com/2020/04/14/异步编程-从高并发爬虫看异步编程/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://a2u13.com" target="_blank">A2u13's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/">异步编程</a></div><div class="post_share"><div class="social-share" data-image="https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/20200710144709.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/06/06/JavaScript%E9%97%AD%E5%8C%85/"><img class="prev_cover" src="https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/20200529223757.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">JavaScript闭包</div></div></a></div><div class="next-post pull_right"><a href="/2020/03/28/%E5%85%A5%E4%BE%B5%E5%93%8D%E5%BA%94%E4%B8%8E%E5%BA%94%E6%80%A5%E6%95%B4%E7%90%86/"><img class="next_cover" src="https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/20200529223045.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">入侵响应与应急整理</div></div></a></div></nav></article></main><footer id="footer" style="background-image: url(https://a2u13-pic.oss-accelerate.aliyuncs.com/pic/20200529223726.png)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2020 By A2u13</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@3/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js"></script><script>document.addEventListener('DOMContentLoaded', function() {
      pangu.spacingElementById('content-inner')
})</script><script src="/js/search/local-search.js"></script></body></html>